{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(w.rstrip() for w in open('stopwords.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = BeautifulSoup(open('electronics/positive.review').read(), features='html5lib')\n",
    "positive_reviews = positive_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews = BeautifulSoup(open('electronics/negative.review').read(), features='html5lib')\n",
    "negative_reviews = negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = positive_reviews[0]\n",
    "# nltk.tokenize.word_tokenize(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s = s.lower()\n",
    "    tokens = nltk.tokenize.word_tokenize(s)\n",
    "    tokens = [t for t in tokens if len(t) > 2]\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens]\n",
    "    tokens = [t for t in tokens if t not in stopwords]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_map = {}\n",
    "current_index = 0\n",
    "positive_tokenized = []\n",
    "negative_tokenized = []\n",
    "orig_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of word index map:  10950\n"
     ]
    }
   ],
   "source": [
    "for review in positive_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "            \n",
    "for review in negative_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "            \n",
    "print(\"Length of word index map: \", len(word_index_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_vector(tokens, label):\n",
    "    x = np.zeros(len(word_index_map) + 1)\n",
    "    for t in tokens:\n",
    "        i = word_index_map[t]\n",
    "        x[i] += 1\n",
    "    x = x / x.sum()\n",
    "    x[-1] = label\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(positive_tokenized) + len(negative_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((N, len(word_index_map) + 1))\n",
    "i = 0\n",
    "for tokens in positive_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 1)\n",
    "    data[i,:] = xy\n",
    "    i += 1\n",
    "\n",
    "for tokens in negative_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 0)\n",
    "    data[i,:] = xy\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_reviews, data = shuffle(orig_reviews, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:-100,]\n",
    "y_train = y[:-100,]\n",
    "X_test = X[-100:,]\n",
    "y_test = y[-100:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7889473684210526\n",
      "Test accuracy:  0.72\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", model.score(X_train, y_train))\n",
    "print(\"Test accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit -0.6935921505296557\n",
      "bad -0.7858194467278309\n",
      "cable 0.7086086684224746\n",
      "time -0.7098574094388858\n",
      "'ve 0.6500090753228062\n",
      "month -0.698716990803417\n",
      "sound 1.1094332567567013\n",
      "lot 0.7173555822879234\n",
      "you 0.966805563268342\n",
      "n't -1.9988707616204693\n",
      "easy 1.8258145082749617\n",
      "quality 1.4758444161255868\n",
      "company -0.5685874311539166\n",
      "item -0.8736159276745926\n",
      "wa -1.5246736843015476\n",
      "perfect 0.9475780059370699\n",
      "fast 0.9365960029534408\n",
      "ha 0.7104662273086592\n",
      "price 2.759414665118117\n",
      "value 0.5561283494330639\n",
      "money -1.079085979759981\n",
      "memory 0.9591542351924246\n",
      "picture 0.6374432009003663\n",
      "buy -0.9011083429966401\n",
      "bit 0.6179072265320875\n",
      "happy 0.6677758379058613\n",
      "pretty 0.760676965279075\n",
      "doe -1.3133971480868674\n",
      "highly 1.06845440270625\n",
      "recommend 0.7341123317382232\n",
      "fit 0.5242329315335003\n",
      "customer -0.6037751948498684\n",
      "support -0.869308465633903\n",
      "little 0.9800292445086\n",
      "returned -0.7955713325302244\n",
      "excellent 1.3805399092824542\n",
      "love 1.0648198836359057\n",
      "home 0.5377267201159748\n",
      "week -0.7704642373838138\n",
      "size 0.5346661528567712\n",
      "using 0.6383877191526772\n",
      "laptop 0.5538869680685086\n",
      "video 0.5749887507572222\n",
      "poor -0.8000528399008943\n",
      "look 0.5852864466914781\n",
      "then -1.0211986098559873\n",
      "tried -0.7958298152533622\n",
      "static -0.5144276527666692\n",
      "radio -0.5179818416896925\n",
      "try -0.6886299645763919\n",
      "space 0.5413070316459621\n",
      "comfortable 0.6671112281002719\n",
      "hour -0.5923599899826856\n",
      "expected 0.5763493651425269\n",
      "speaker 0.8913457097560215\n",
      "warranty -0.6159153825924046\n",
      "junk -0.5554676491598576\n",
      "returning -0.5397116518520012\n",
      "paper 0.5463739201671508\n",
      "terrible -0.5080072680676906\n",
      "return -1.2437868704903878\n",
      "waste -1.0224721063730977\n",
      "refund -0.6451129948910049\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "for word, index in iteritems(word_index_map):\n",
    "    weight = model.coef_[0][index]\n",
    "    if weight > threshold or weight < -threshold:\n",
    "        print(word, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X)\n",
    "P = model.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "minP_whenYis1 = 1\n",
    "maxP_whenYis0 = 0\n",
    "wrong_positive_review = None\n",
    "wrong_negative_review = None\n",
    "wrong_positive_prediction = None\n",
    "wrong_negative_prediction = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    p = P[i]\n",
    "    Y = y[i]\n",
    "    if Y == 1 and p < 0.5:\n",
    "        if p < minP_whenYis1:\n",
    "            wrong_positive_review = orig_reviews[i]\n",
    "            wrong_positive_prediction = preds[i]\n",
    "            minP_whenYis1 = p\n",
    "    elif Y == 0 and p > 0.5:\n",
    "        if p > maxP_whenYis0:\n",
    "            wrong_negative_review = orig_reviews[i]\n",
    "            wrong_negative_prediction = preds[i]\n",
    "            maxP_whenYis0 = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most wrong positive review prob = 0.34953533049044305, pred = 0.0\n",
      "\n",
      "A device like this either works or it doesn't.  This one happens to work\n",
      "\n",
      "Most wrong negative review prob = 0.602798660943189, pred = 1.0\n",
      "\n",
      "The Voice recorder meets all my expectations and more\n",
      "Easy to use, easy to transfer great results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Most wrong positive review prob = {}, pred = {}\".format(minP_whenYis1, wrong_positive_prediction))\n",
    "print(wrong_positive_review)\n",
    "print(\"Most wrong negative review prob = {}, pred = {}\".format(maxP_whenYis0, wrong_negative_prediction))\n",
    "print(wrong_negative_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
